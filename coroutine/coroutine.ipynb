{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "OK url_1\n",
      "crawling url_2\n",
      "OK url_2\n",
      "crawling url_3\n",
      "OK url_3\n",
      "crawling url_4\n",
      "OK url_4\n",
      "CPU times: user 3.77 ms, sys: 486 Âµs, total: 4.25 ms\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    time.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "\n",
    "def main(urls):\n",
    "    for url in urls:\n",
    "        crawl_page(url)\n",
    "\n",
    "%time main(['url_1', 'url_2', 'url_3', 'url_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "\n",
    "async def main(urls):\n",
    "    for url in urls:\n",
    "        await crawl_page(url)\n",
    "\n",
    "%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    print('OK {}'.format(url))\n",
    "\n",
    "async def main(urls):\n",
    "    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]\n",
    "    for task in tasks:\n",
    "        await task\n",
    "\n",
    "%time asyncio.run(main(['url_1', 'url_2', 'url_3', 'url_4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "1 2 3 4 5\n"
     ]
    }
   ],
   "source": [
    "l1=[1,2,3,4,5]\n",
    "print(l1)\n",
    "print(*l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crawling url_1\n",
      "crawling url_2\n",
      "crawling url_3\n",
      "crawling url_4\n",
      "result: OK url_1\n",
      "result: OK url_2\n",
      "result: OK url_3\n",
      "result: OK url_4\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def crawl_page(url):\n",
    "    print('crawling {}'.format(url))\n",
    "    sleep_time = int(url.split('_')[-1])\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    return 'OK {}'.format(url)\n",
    "\n",
    "async def main(urls):\n",
    "    tasks = [asyncio.create_task(crawl_page(url)) for url in urls]\n",
    "    for task in tasks:\n",
    "        task.add_done_callback(lambda future: print('result: {}'.format(future.result())))\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "await main(['url_1', 'url_2', 'url_3', 'url_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 69447 from https://en.wikipedia.org/wiki/Go_(programming_language)\n",
      "result: None\n",
      "Read 37248 from https://en.wikipedia.org/wiki/Portal:Society\n",
      "Read 16891 from https://en.wikipedia.org/wiki/The_C_Programming_Language\n",
      "result: None\n",
      "result: None\n",
      "Read 72897 from https://en.wikipedia.org/wiki/Portal:Geography\n",
      "result: None\n",
      "Read 47551 from https://en.wikipedia.org/wiki/Portal:Arts\n",
      "result: None\n",
      "Read 65540 from https://en.wikipedia.org/wiki/Portal:Technology\n",
      "result: None\n",
      "Read 77157 from https://en.wikipedia.org/wiki/Computer_science\n",
      "result: None\n",
      "Read 39793 from https://en.wikipedia.org/wiki/Node.js\n",
      "result: None\n",
      "Read 74914 from https://en.wikipedia.org/wiki/Portal:History\n",
      "result: None\n",
      "Read 57761 from https://en.wikipedia.org/wiki/Portal:Science\n",
      "result: None\n",
      "Read 67719 from https://en.wikipedia.org/wiki/Portal:Mathematics\n",
      "result: None\n",
      "Read 97493 from https://en.wikipedia.org/wiki/PHP\n",
      "result: None\n",
      "Read 85761 from https://en.wikipedia.org/wiki/Portal:Biography\n",
      "result: None\n",
      "Read 68055 from https://en.wikipedia.org/wiki/Java_(programming_language)\n",
      "result: None\n",
      "Read 99125 from https://en.wikipedia.org/wiki/Python_(programming_language)\n",
      "result: None\n",
      "Download 15 sites in 4.917324992999966 seconds\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from aiohttp_proxy import ProxyConnector, ProxyType\n",
    "import time\n",
    "\n",
    "async def download_one(url):\n",
    "    connector = ProxyConnector.from_url('http://172.28.16.1:10811')\n",
    "    async with aiohttp.ClientSession(connector=connector) as session:\n",
    "        async with session.get(url) as resp:\n",
    "            print('Read {} from {}'.format(resp.content_length, url))\n",
    "\n",
    "\n",
    "async def main(sites):\n",
    "    tasks = [asyncio.create_task(download_one(site)) for site in sites]\n",
    "    for task in tasks:\n",
    "        task.add_done_callback(lambda future: print(\n",
    "            'result: {}'.format(future.result())))\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "sites = [\n",
    "    'https://en.wikipedia.org/wiki/Portal:Arts',\n",
    "    'https://en.wikipedia.org/wiki/Portal:History',\n",
    "    'https://en.wikipedia.org/wiki/Portal:Society',\n",
    "    'https://en.wikipedia.org/wiki/Portal:Biography',\n",
    "    'https://en.wikipedia.org/wiki/Portal:Mathematics',\n",
    "    'https://en.wikipedia.org/wiki/Portal:Technology',\n",
    "    'https://en.wikipedia.org/wiki/Portal:Geography',\n",
    "    'https://en.wikipedia.org/wiki/Portal:Science',\n",
    "    'https://en.wikipedia.org/wiki/Computer_science',\n",
    "    'https://en.wikipedia.org/wiki/Python_(programming_language)',\n",
    "    'https://en.wikipedia.org/wiki/Java_(programming_language)',\n",
    "    'https://en.wikipedia.org/wiki/PHP',\n",
    "    'https://en.wikipedia.org/wiki/Node.js',\n",
    "    'https://en.wikipedia.org/wiki/The_C_Programming_Language',\n",
    "    'https://en.wikipedia.org/wiki/Go_(programming_language)'\n",
    "]\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "await main(sites)\n",
    "end_time = time.perf_counter()\n",
    "print('Download {} sites in {} seconds'.format(len(sites), end_time - start_time))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geekbang-python-core",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "80c78d802a3c1cded24c666231dc8c172ce01ee8af83719d58c29c99aa9f4b00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
